{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7defafc9",
   "metadata": {},
   "source": [
    "# EEG Data Loader for Neural Processing of Nonsense Study\n",
    "\n",
    "This notebook provides an interactive interface for loading and processing EEG data from the Neural Processing of Nonsense experiment. The data consists of complex frequency-domain coefficients from 32 electrodes across 4 experimental conditions.\n",
    "\n",
    "## Experimental Conditions:\n",
    "- **GN**: Grammatical Nonsense (trials 1-30)\n",
    "- **GS**: Grammatical Sensible (trials 31-60)  \n",
    "- **UN**: Ungrammatical Nonsense (trials 61-90)\n",
    "- **US**: Ungrammatical Sensible (trials 91-120)\n",
    "\n",
    "## Data Structure:\n",
    "- **participant**: Subject ID (S1, S2, etc.)\n",
    "- **frequency**: Frequency values in Hz (0.3-4.0 Hz range)\n",
    "- **electrode**: Electrode names (32 channels)\n",
    "- **trial**: Trial number (1-120)\n",
    "- **coeff**: Complex frequency coefficients\n",
    "- **condition**: Experimental condition (GN, GS, UN, US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6046cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 3,118,080 rows | 14 participants | 32 electrodes\n",
      "Conditions: GN, GS, UN, US\n",
      "Frequency range: 0.3-4.0 Hz (58 values)\n",
      "  GN: 779,520\n",
      "  GS: 779,520\n",
      "  UN: 779,520\n",
      "  US: 779,520\n",
      "✓ Saved to: data/combined_eeg_data.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"EEG Data Loader for Neural Processing of Nonsense Study\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def load_freq_electrode_info(csv_dir):\n",
    "    \"\"\"Load frequency and electrode info, returning defaults if file missing\"\"\"\n",
    "    try:\n",
    "        file_path = Path(csv_dir) / \"freq&channels.csv\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Parse electrodes from first line\n",
    "        electrodes = lines[0].strip().split(',')\n",
    "        \n",
    "        # Parse frequencies from third line (index 2)\n",
    "        frequencies = [float(x) for x in lines[2].strip().split(',')]\n",
    "        \n",
    "        return electrodes, frequencies\n",
    "    except:\n",
    "        return [f\"Ch{i+1}\" for i in range(32)], list(range(58))\n",
    "\n",
    "\n",
    "def get_condition(trial):\n",
    "    \"\"\"Map trial number to condition (GN: 1-30, GS: 31-60, UN: 61-90, US: 91-120)\"\"\"\n",
    "    return ['GN', 'GS', 'UN', 'US'][(trial - 1) // 30] if 1 <= trial <= 120 else 'Unknown'\n",
    "\n",
    "\n",
    "def load_csv_file(filepath, electrodes, frequencies):\n",
    "    \"\"\"Load and process a single CSV file\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(filepath, header=None)\n",
    "        if data.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        participant = re.search(r'(S\\d+)', filepath.name).group(1)\n",
    "        rows = []\n",
    "\n",
    "        for _, row in data.iterrows():\n",
    "            trial, electrode_idx = int(row.iloc[0]), int(row.iloc[1]) - 1\n",
    "            electrode = electrodes[electrode_idx] \n",
    "\n",
    "            for freq_idx, val in enumerate(row.iloc[2:]):\n",
    "                if pd.notna(val) and val != '':\n",
    "                    try:\n",
    "                        coeff = complex(str(val).replace('i', 'j'))\n",
    "                        if pd.notna(coeff):\n",
    "                            rows.append([participant, frequencies[freq_idx] ,\n",
    "                                         electrode, trial, coeff, get_condition(trial)])\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        return pd.DataFrame(rows, columns=['participant', 'frequency', 'electrode', 'trial', 'coeff', 'condition'])\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def load_all_eeg_data(csv_dir):\n",
    "    \"\"\"Load all CSV files and create comprehensive dataframe\"\"\"\n",
    "    csv_dir = Path(csv_dir)\n",
    "    electrodes, frequencies = load_freq_electrode_info(csv_dir)\n",
    "\n",
    "    csv_files = list(csv_dir.glob(\"*_main.csv\"))\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No *_main.csv files found in {csv_dir}\")\n",
    "\n",
    "    dataframes = [load_csv_file(f, electrodes, frequencies) for f in csv_files]\n",
    "    dataframes = [df for df in dataframes if not df.empty]\n",
    "\n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No data loaded from any files\")\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True).sort_values(\n",
    "        ['participant', 'trial', 'electrode', 'frequency']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Load EEG data\n",
    "try:\n",
    "    df = load_all_eeg_data(\"data/csv_files\")\n",
    "    \n",
    "    # Save data\n",
    "    output_file = \"data/combined_eeg_data.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Brief summary\n",
    "    print(f\"Dataset: {len(df):,} rows | {df['participant'].nunique()} participants | {df['electrode'].nunique()} electrodes\")\n",
    "    print(f\"Conditions: {', '.join(sorted(df['condition'].unique()))}\")\n",
    "    print(f\"Frequency range: {df['frequency'].min():.1f}-{df['frequency'].max():.1f} Hz ({df['frequency'].nunique()} values)\")\n",
    "    for condition, count in df['condition'].value_counts().items():\n",
    "        print(f\"  {condition}: {count:,}\")\n",
    "    print(f\"✓ Saved to: {output_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb085068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in directory: C:\\Users\\Me\\data\\csv_files\n",
      "Directory exists: True\n",
      "All files in directory: 34\n",
      "  .ipynb_checkpoints\n",
      "  freq&channels.csv\n",
      "  S10_17_07_2018_ft_coeff.csv\n",
      "  S10_17_07_2018_main.csv\n",
      "  S11_17_07_2018_ft_coeff.csv\n",
      "  S11_17_07_2018_main.csv\n",
      "  S12_18_07_2018_ft_coeff.csv\n",
      "  S12_18_07_2018_main.csv\n",
      "  S13_19_07_2018_ft_coeff.csv\n",
      "  S13_19_07_2018_main.csv\n",
      "*_main.csv files found: 16\n",
      "  S10_17_07_2018_main.csv\n",
      "  S11_17_07_2018_main.csv\n",
      "  S12_18_07_2018_main.csv\n",
      "  S13_19_07_2018_main.csv\n",
      "  S14_19_07_2018_main.csv\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what files are available\n",
    "from pathlib import Path\n",
    "\n",
    "csv_dir = Path(\"data/csv_files\")\n",
    "print(f\"Looking in directory: {csv_dir.absolute()}\")\n",
    "print(f\"Directory exists: {csv_dir.exists()}\")\n",
    "\n",
    "if csv_dir.exists():\n",
    "    all_files = list(csv_dir.glob(\"*\"))\n",
    "    print(f\"All files in directory: {len(all_files)}\")\n",
    "    for f in all_files[:10]:  # Show first 10 files\n",
    "        print(f\"  {f.name}\")\n",
    "    \n",
    "    main_files = list(csv_dir.glob(\"*_main.csv\"))\n",
    "    print(f\"*_main.csv files found: {len(main_files)}\")\n",
    "    for f in main_files[:5]:  # Show first 5 main files\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(\"Directory does not exist!\")\n",
    "    print(\"Current working directory:\", Path.cwd())\n",
    "    \n",
    "    # Check if data folder exists\n",
    "    data_dir = Path(\"data\")\n",
    "    print(f\"Data directory exists: {data_dir.exists()}\")\n",
    "    if data_dir.exists():\n",
    "        subdirs = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "        print(f\"Subdirectories in data: {[d.name for d in subdirs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1776aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
